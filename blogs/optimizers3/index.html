<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>O3 | Lav-Aniya&#39;s Site</title>
<meta name="keywords" content="Optimization, Deep Learning">
<meta name="description" content="An Introduction to Optimization">
<meta name="author" content="Lav-niya">
<link rel="canonical" href="https://lav-aniya.github.io/blogs/optimizers3/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1f97f95668440377e5dcde099c302fc9dfe0232ee0eb1ce62fb6c6720e6e67b7.css" integrity="sha256-H5f5VmhEA3fl3N4JnDAvyd/gIy7g6xzmL7bGcg5uZ7c=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lav-aniya.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lav-aniya.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lav-aniya.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lav-aniya.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lav-aniya.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lav-aniya.github.io/blogs/optimizers3/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false},
                {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
                {left: "\\begin{align}", right: "\\end{align}", display: true},
                {left: "\\begin{align*}", right: "\\end{align*}", display: true},
                {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                {left: "\\begin{CD}", right: "\\end{CD}", display: true},
            ],
            throwOnError : false
        });
    });
</script>

<meta property="og:url" content="https://lav-aniya.github.io/blogs/optimizers3/">
  <meta property="og:site_name" content="Lav-Aniya&#39;s Site">
  <meta property="og:title" content="O3">
  <meta property="og:description" content="An Introduction to Optimization">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2025-09-22T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-09-22T00:00:00+00:00">
    <meta property="article:tag" content="Optimization">
    <meta property="article:tag" content="Deep Learning">
      <meta property="og:see_also" content="https://lav-aniya.github.io/blogs/optimizers/">
      <meta property="og:see_also" content="https://lav-aniya.github.io/blogs/optimizers2/">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="O3">
<meta name="twitter:description" content="An Introduction to Optimization">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "https://lav-aniya.github.io/blogs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "O3",
      "item": "https://lav-aniya.github.io/blogs/optimizers3/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "O3",
  "name": "O3",
  "description": "An Introduction to Optimization",
  "keywords": [
    "Optimization", "Deep Learning"
  ],
  "articleBody": "This is the third part of the series. You can read the second part here: O2\nAdam: The best of both worlds We’ve seen two main strategies for improving on basic SGD:\nMomentum: This is like a heavy ball that remembers the direction it was going, helping it roll faster and smoother. RMSprop: This is like a smart mechanic with a custom toolkit who adapts the step size for each knob individually. Adam’s brilliant idea was to ask: “Why not do both?”\nThe Intuitive Idea The Big Idea: Adam is the optimizer that combines the “heavy ball” of momentum with the “custom toolkit” of RMSprop. It builds up speed in the right direction while also adapting the learning rate for each and every parameter.\nHow it Works: Adam doesn’t just keep one memories to come up with a smart, custom plan for each knob. It uses the first memory to decide on the direction and the second memory to decide how big of a step to take in that direction.\n“Warm-up” Phase\nAdam has one more clever feature. At the very beginning of training, both of its memories are empty. This can make its first few steps a little small and wonky. Adam has a built-in “warm-up” or bias correction step that fixes this, making sure its first few steps are confident and well calibrated.\nThe Outcome:\nthe result is an optimizer that is incredibly effective and works well right out of the box. For a long time, Adam was the undisputed king and the default choice for almost any deep learning problem because it’s fast, reliable, and requires less manual tuning of the learning rate.\nThe Technical Dive The name Adam stands for Adaptive Moment Estimation. This name tells you exactly what it does: it adapts the parameter updates based on estimates of the first and second moments of the gradients.\nAdam’s algorithm looks comples, but it’s just the ideas from Momentum and RMSprop combined, plus a correction step.\nThe Algorithm: At each time step $t$, for each parameter:\n1. The 1st Moment ($m_{t}$): The “Momentum” Part The first moment is simply the mean (or average) of the gradients. Adam calculates this using an exponentially weighted moving average:\n$$ m_{t} = \\beta_{1} m_{t-1} + (1 - \\beta_{1}) g_{t} $$\nThis is almost identical to the velocity vector in the Momentum optimizer. It keeps track of the direction of the recent gradients.\nWhat it does: It tells the optimizer the general direction it should be heading. If the gradients have consistently been pointing downhill to the right, $m_{t}$ will be a strong vector pointing in that same direction. This is what helps Adam accelerate and smooth its path. The $\\beta_{1}$ knob: This decay rate controls how long the “memory” of past directions is. A typical value of 0.9 means the current estimate is 90% of the old memory and 10% of the new gradient’s direction. 2. The 2nd Moment ($v_{t}$): The “Adaptive” Part The second moment is the uncentered variance of the gradients. Again, it’s calculated with a moving average, but this time on the squared gradients:\n$$ v_{t} = \\beta_{2} v_{t-1} + (1 - \\beta_{2}) g_{t}^{2} $$\nThis is almost identical to the memory component in RMSprop. It tracks the average magnitude (or “size”) of recent gradients for each parameter.\nWhat it does: It tells the optimizer how “active” or “noisy” each parameter has been. If a parameter’s gradient has been consistently large, its $v_{t}$ will be large. This is used to shrink the step size for that specific parameter. The $\\beta_{2}$ knob: This decay rate controls the memory span for the gradient sizes. A typical value of 0.999 means it has a much longer memory than the 1st moment, making the adaptation of the learning rate more stable. 3. Bias Correction: This is the most unique part of Adam. So, why is it needed?\nThe formal Derivation of Bias\nlet’s analyze the expected values of the first moment estimate $m_{t}$, assuming the true gradients $g_{i}$ are drawn from a stationary distribution with mean $E[g]$. The expanded formula for $m_{t}$ is an exponentially weighted sum:\n$$ m_{t} = (1 - \\beta_{1}) \\sum_{i=1}^{t} \\beta_{1}^{t-i} g_{i} $$\ntaking expectation of both sides, we get : $$E[m_t] = E\\left[(1-\\beta_1)\\sum_{i=1}^{t} \\beta_1^{t-i} g_i\\right] = (1-\\beta_1)\\sum_{i=1}^{t} \\beta_1^{t-i} E[g_i]$$\nSince $E[g_i] = E[g]$, we can factor it out:\n$$E[m_t] = E[g] \\cdot (1-\\beta_1)\\sum_{i=1}^{t} \\beta_1^{t-i}$$\nThe summation is a finite geometric series, which simplifies to $\\frac{1-\\beta_{1}^{t}}{1-\\beta_{1}}$. Substituting this back in gives us the final result:\n$$ E[m_{t}] = E[g] \\cdot (1 - \\beta_1) (\\frac{1 - \\beta_1^t}{1 - \\beta_1}) = E[g] \\cdot (1 - \\beta_1^t) $$\nThis proves that the expected value of our moment estimate $m_t$ is not the true moment $E[g]$. It is off by a factor of $(1-\\beta_1^t)$. This is the mathematical definition of the bias.\nA Practical Example: A Cold Start:\nBoth $m_{t}$ and $v_{t}$ are initialized as vectors of zeros. Let’s look at what happens on the very first step ($t=1$), with $\\beta_{1} = 0.9$:\n$$ m_{1} = 0.9 \\cdot (0) + 0.1 \\cdot g_{1} = 0.1 \\cdot g_{1} $$\nThe first moment estimate is only 10% of the actual first gradient. The estimate is heavily biased towards zero, exactly as our derived bias factor of $(1 - 0.9^1) = 0.1$ predicted. This makes the initial steps of the optimizer unnecessarily small and inefficient. It needs a “warm-up” period for the moment estimates to catch up to their true values.\nDeriving the Correction:\nTo create an unbiased estimator $\\hat{m}_t$ such that $E[\\hat{m}_t] = E[g]$, we simply need to counteract the bias factor we derived. Starting from our result:\n$$E[m_t] = E[g] (1-\\beta_1^t)$$We can rearrange it to define an unbiased estimate of $E[g]$:\n$$E[g] = \\frac{E[m_t]}{1-\\beta_1^t} = E\\left[\\frac{m_t}{1-\\beta_1^t}\\right]$$\nThis directly gives us the bias-corrected estimators for both moments:\n$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} \\quad \\text{and} \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\nLet’s see this correction in action on our $t=1$ example:\n$$\\hat{m}_1 = \\frac{m_1}{1 - 0.9^1} = \\frac{0.1 \\cdot g_1}{0.1} = g_1$$\nThe correction perfectly cancels the bias, ensuring the estimate is accurate from the very first step.\n4. Putting It All Together: The Final Update Rule The final update rule is a combination:\n$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v} + \\epsilon}} \\hat{m_{t}}$$\nWe take the direction from the corrected 1st moment, $\\hat{m}_t$ (the Momentum part). We divide it by the square root of the corrected 2nd moment, $\\sqrt{\\hat{v}_t}$ (the RMSprop part), which normalizes the step size on a per-parameter basis. We scale the whole thing by a global learning rate $\\eta$. This is how Adam effectively takes the best from its predecessors and combines them into a single, robust algorithm.\nAdamW [Adam with Decoupled Weight Decay] As models, especially Transformers became more comples, something was bit off with how Adam handled a common regularization technique called weight decay. AdamW is the fix.\nThe Intuitive Idea The Problem: To prevent our models from getting too complex and “memorizing” the training data (overfitting), we often use a technique called L2 Regularization. Think of it as a penalty for having large parameter values. It encourages the model to keep its “knobs” (weights) small and simple.\nIn optimizers like SGD, this is implemented as weight decay, where you subtract a tiny fraction of the weight from itself at every step. It’s like a small tax on the weights, forcing them to shrink, or “decay,” over time.\nWe assumed L2 Regularization and weight decay were the same thing and implemented them that way. So, Adam’s implementation mixed the weight decay “tax” in with the gradient.\nThe Big Idea: Imagine you’re trying to roll our “heavy ball” (from Momentum) downhill. The gradient is the force of gravity pulling it down the slope. Weight decay is like a gentle, constant breeze that always pushes the ball towards the center of the valley (towards zero).\nAdam’s Mistake: Adam mixed the “breeze” (weight decay) in with the “gravity” (gradient). This seems fine, but Adam’s adaptive machinery ($\\sqrt{\\hat{v}_t}$) scales both forces together. So, if a parameter has had large gradients in the past, Adam shrinks the learning rate for both the gravity and the breeze for that parameter. The breeze shouldn’t be scaled; it should be constant. AdamW’s Fix: AdamW (Adam with Weight Decay) is simple. It says, “Don’t mix the two forces.” It first calculates the step using only gravity (the gradient), just like regular Adam. Then, as a completely separate step, it applies the gentle breeze (the weight decay tax). This is called decoupled weight decay. The Outcome: This simple change makes a huge difference. The regularization becomes much more effective and predictable. For training large models like Transformers, AdamW almost always performs better than Adam and is now the recommended default optimizer.\nThe Techincal Dive The difference between Adam and AdamW is subtle but mathematically significant. It all comes down to how L2 regularization is implemented.\nL2 Regularizatoin vs Weight Decay in its pure form, L2 Regularization modifies the loss function by adding a penalty term:\n$$J_{L2}(\\theta) = J_{original}(\\theta) + \\frac{\\lambda}{2} \\sum_{i} \\theta_{i}^{2} $$\nWhen you take the derivative of this new loss function, the gradient becomes:\n$$ \\nabla_{\\theta} J_{L2} (\\theta) = \\nabla_{\\theta} J_{original} (\\theta) + \\lambda \\theta $$ Here, $\\lambda$ is the regularization strength.\nHow Adam Implements It (Incorrectly): Adaptive optimizers like Adam use moving averages ($m_t$ and $v_t$) of the gradient. In standard libraries, the L2 term ($\\lambda\\theta$) was simply added to the gradient $g_t$ before being passed to the optimizer.\nL2 regularization results in a gradient of $g_t + \\lambda\\theta_t$, where $g_t = \\nabla_{\\theta}J_{original}(\\theta_t)$.\nWhen this combined gradient is fed into the Adam algorithm, the moment estimates become:\n1st Moment: $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) (g_t + \\lambda\\theta_t)$ 2nd Moment: $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (g_t + \\lambda\\theta_t)^2$ The final update rule (ignoring bias correction for simplicity) is: $$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{v_t} + \\epsilon} m_t$$ Notice that the weight decay term $\\lambda\\theta_t$ is now inside the moving averages. This means the adaptive denominator $\\sqrt{v_t}$ scales both the gradient and the weight decay. If a particular weight has a large historical gradient magnitude, its corresponding $v_t$ will be large. This shrinks the update from the original gradient (which is desirable) but also shrinks the effect of the weight decay $\\lambda\\theta_t$ (which is not). The regularization becomes less effective for parameters that need it most.\nHow AdamW Implements Weight Decay (The Decoupled Approach): AdamW decouples the weight decay from the gradient update.\nThe moment estimates are updated using only the original gradient $g_t$:\n1st Moment: $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$\n2nd Moment: $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$\nThe adaptive Adam step is calculated from these moments::\n$$(\\text{Adam Step})_t = \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\nwhere $m_t$ and $v_t$ are computed using only $\\nabla_{\\theta}J_{original}(\\theta_t)$.\nThe final update applies this step and then subtracts the decay term directly:\n$$\\theta_{t+1} = \\theta_t - (\\text{Adam Step})_t - \\eta \\lambda \\theta_t$$\nCrucially, the weight decay term - $\\eta \\lambda \\theta_t$ is not affected by the adaptive moment estimates. The decay is proportional only to the weight’s current value and the learning rate, making the regularization behave exactly as intended.\nThis decoupling ensures that the optimizer’s adaptivity is used to navigate the loss landscape (via the gradients), while weight decay serves its distinct purpose as a regularizer, shrinking weights towards zero at a predictable rate. This makes training more stable and allows for better generalization, particularly in models sensitive to regularization like Transformers.\nThe Practical Impact: Better Hyperparameter Tuning The main benefit of decoupling is that it makes the hyperparameters easier to tune and more independent of each other.\nThink of it like tuning an old stereo system:\nIn Standard Adam: the learning rate ($\\eta$) and the L2 regularization factor ($\\lambda$) are coupled. This is because the weight decay term $\\lambda\\theta_t$ is included in the gradient before the moment estimation. Consequently, the final update for a given parameter is scaled by $\\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon}$. This means the effective weight decay is influenced by both $\\lambda$ and the historical gradients stored in $\\hat{v}_t$. As a result, changing the learning rate $\\eta$ or the initial parameter scale alters the effective magnitude of the weight decay, making it difficult to tune the two hyperparameters independently.\nin AdamW: the weight decay is decoupled from the adaptive mechanism. The update from weight decay is simply $- \\eta \\lambda \\theta_t$. The effect of the $\\lambda$ hyperparameter is now scaled only by the learning rate $\\eta$, not by the adaptive denominator $\\sqrt{\\hat{v}_t}$ which contains the gradient history. This makes the relationship between the learning rate and weight decay much more predictable. You can tune the regularization strength $\\lambda$ with a more consistent expectation of its effect, regardless of the adaptivity, creating a more orthogonal and effective search for optimal hyperparameters.\nThis decoupling allows you to find better final models because the optimal learning rate is less dependent on your choice of weight decay, and vice-versa. You have finer control, which often leads to better overall performance.\nWith Learning Rate Schedulers Decoupled weight decay works much better with learning rate schedulers (like cosine annealing, where the learning rate starts high and gradually decreases).\nWith standard Adam, as the learning rate $\\eta$ decays, the effective strength of the weight decay also shrinks in a coupled, often unpredictable way. With AdamW, the effect is cleaner. This allows for more aggressive learning rate schedules, which can help the model settle into better, wider minima in the loss landscape, further improving generalization.\n",
  "wordCount" : "2248",
  "inLanguage": "en",
  "datePublished": "2025-09-22T00:00:00Z",
  "dateModified": "2025-09-22T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Lav-niya"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lav-aniya.github.io/blogs/optimizers3/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lav-Aniya's Site",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lav-aniya.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lav-aniya.github.io/" accesskey="h" title="Lav-Aniya&#39;s Site (Alt + H)">Lav-Aniya&#39;s Site</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://github.com/Lav-aniya" title="&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;&lt;path d=&#34;M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22&#34;&gt;&lt;/path&gt;&lt;/svg&gt;">
                    <span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></span>
                    
                </a>
            </li>
            <li>
                <a href="https://www.linkedin.com/in/your-profile-name/" title="&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;&lt;path d=&#34;M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z&#34;&gt;&lt;/path&gt;&lt;rect x=&#34;2&#34; y=&#34;9&#34; width=&#34;4&#34; height=&#34;12&#34;&gt;&lt;/rect&gt;&lt;circle cx=&#34;4&#34; cy=&#34;4&#34; r=&#34;2&#34;&gt;&lt;/circle&gt;&lt;/svg&gt;">
                    <span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg></span>
                    
                </a>
            </li>
            <li>
                <a href="mailto:lavaniya.nen@gmail.com" title="&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt;&lt;path d=&#34;M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z&#34;&gt;&lt;/path&gt;&lt;polyline points=&#34;22,6 12,13 2,6&#34;&gt;&lt;/polyline&gt;&lt;/svg&gt;">
                    <span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg></span>
                    
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      O3
    </h1>
    <div class="post-description">
      An Introduction to Optimization
    </div>
    <div class="post-meta"><span title='2025-09-22 00:00:00 +0000 UTC'>September 22, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;Lav-niya

</div>
  </header> 
  <div class="post-content"><p>This is the third part of the series. You can read the second part here: <a href="/blogs/optimizers2/">O2</a></p>
<h2 id="adam-the-best-of-both-worlds">Adam: The best of both worlds<a hidden class="anchor" aria-hidden="true" href="#adam-the-best-of-both-worlds">#</a></h2>
<p>We&rsquo;ve seen two main strategies for improving on basic SGD:</p>
<ol>
<li><strong>Momentum:</strong> This is like a heavy ball that remembers the <em>direction</em> it was going, helping it roll faster and smoother.</li>
<li><strong>RMSprop:</strong> This is like a smart mechanic with a custom toolkit who adapts the <em>step size</em> for each knob individually.</li>
</ol>
<p>Adam&rsquo;s brilliant idea was to ask: &ldquo;Why not do both?&rdquo;</p>
<h3 id="the-intuitive-idea"><em><strong>The Intuitive Idea</strong></em><a hidden class="anchor" aria-hidden="true" href="#the-intuitive-idea">#</a></h3>
<p><strong>The Big Idea:</strong> Adam is the optimizer that combines the &ldquo;heavy ball&rdquo; of momentum with the &ldquo;custom toolkit&rdquo; of RMSprop. It builds up speed in the right direction while also adapting the learning rate for each and every parameter.</p>
<p><strong>How it Works:</strong> Adam doesn&rsquo;t just keep one memories to come up with a smart, custom plan for each knob. It uses the first memory to decide on the direction and the second memory to decide how big of a step to take in that direction.</p>
<p><strong>&ldquo;Warm-up&rdquo; Phase</strong></p>
<p>Adam has one more clever feature. At the very beginning of training, both of its memories are empty. This can make its first few steps a little small and wonky. Adam has a built-in &ldquo;warm-up&rdquo; or <strong>bias correction</strong> step that fixes this, making sure its first few steps are confident and well calibrated.</p>
<p><strong>The Outcome:</strong></p>
<p>the result is an optimizer that is incredibly effective and works well right out of the box. For a long time, Adam was the undisputed king and the default choice for almost any deep learning problem because it&rsquo;s fast, reliable, and requires less manual tuning of the learning rate.</p>
<hr>
<h3 id="the-technical-dive"><em><strong>The Technical Dive</strong></em><a hidden class="anchor" aria-hidden="true" href="#the-technical-dive">#</a></h3>
<p>The name <strong>Adam</strong> stands for Adaptive Moment Estimation. This name tells you exactly what it does: it adapts the parameter updates based on estimates of the first and second moments of the gradients.</p>
<p>Adam&rsquo;s algorithm looks comples, but it&rsquo;s just the ideas from Momentum and RMSprop combined, plus a correction step.</p>
<h4 id="the-algorithm"><strong>The Algorithm:</strong><a hidden class="anchor" aria-hidden="true" href="#the-algorithm">#</a></h4>
<p>At each time step $t$, for each parameter:</p>
<h4 id="1-the-1st-moment-m_"><strong>1. The 1st Moment ($m_{t}$): The &ldquo;Momentum&rdquo; Part</strong><a hidden class="anchor" aria-hidden="true" href="#1-the-1st-moment-m_">#</a></h4>
<p>The first moment is simply the <strong>mean</strong> (or average) of the gradients. Adam calculates this using an exponentially weighted moving average:</p>
<p>$$ m_{t} = \beta_{1} m_{t-1} + (1 - \beta_{1}) g_{t} $$</p>
<p>This is almost identical to the velocity vector in the Momentum optimizer. It keeps track of the <strong>direction of the recent gradients.</strong></p>
<ul>
<li><strong>What it does:</strong> It tells the optimizer the general direction it should be heading. If the gradients have consistently been pointing downhill to the right, $m_{t}$ will be a strong vector pointing in that same direction. This is what helps Adam accelerate and smooth its path.</li>
<li><strong>The $\beta_{1}$ knob:</strong> This decay rate controls how long the &ldquo;memory&rdquo; of past directions is. A typical value of 0.9 means the current estimate is 90% of the old memory and 10% of the new gradient&rsquo;s direction.</li>
</ul>
<h4 id="2-the-2nd-moment-v_"><strong>2. The 2nd Moment ($v_{t}$): The &ldquo;Adaptive&rdquo; Part</strong><a hidden class="anchor" aria-hidden="true" href="#2-the-2nd-moment-v_">#</a></h4>
<p>The second moment is the <strong>uncentered variance</strong> of the gradients. Again, it&rsquo;s calculated with a moving average, but this time on the squared gradients:</p>
<p>$$ v_{t} = \beta_{2} v_{t-1} + (1 - \beta_{2}) g_{t}^{2} $$</p>
<p>This is almost identical to the memory component in RMSprop. It tracks the <strong>average magnitude</strong> (or &ldquo;size&rdquo;) of recent gradients for each parameter.</p>
<ul>
<li><strong>What it does:</strong> It tells the optimizer how &ldquo;active&rdquo; or &ldquo;noisy&rdquo; each parameter has been. If a parameter&rsquo;s gradient has been consistently large, its $v_{t}$ will be large. This is used to shrink the step size for that specific parameter.</li>
<li><strong>The $\beta_{2}$ knob:</strong> This decay rate controls the memory span for the gradient sizes. A typical value of 0.999 means it has a much longer memory than the 1st moment, making the adaptation of the learning rate more stable.</li>
</ul>
<h4 id="3-bias-correction"><strong>3. Bias Correction:</strong><a hidden class="anchor" aria-hidden="true" href="#3-bias-correction">#</a></h4>
<p>This is the most unique part of Adam. So, why is it needed?</p>
<p><strong>The formal Derivation of Bias</strong></p>
<p>let&rsquo;s analyze the expected values of the first moment estimate $m_{t}$, assuming the true gradients $g_{i}$ are drawn from a stationary distribution with mean $E[g]$.
The expanded formula for $m_{t}$ is an exponentially weighted sum:</p>
<p>$$ m_{t} = (1 - \beta_{1}) \sum_{i=1}^{t} \beta_{1}^{t-i} g_{i} $$</p>
<p>taking expectation of both sides, we get :
$$E[m_t] = E\left[(1-\beta_1)\sum_{i=1}^{t} \beta_1^{t-i} g_i\right] = (1-\beta_1)\sum_{i=1}^{t} \beta_1^{t-i} E[g_i]$$</p>
<p>Since $E[g_i] = E[g]$, we can factor it out:</p>
<p>$$E[m_t] = E[g] \cdot (1-\beta_1)\sum_{i=1}^{t} \beta_1^{t-i}$$</p>
<p>The summation is a finite geometric series, which simplifies to $\frac{1-\beta_{1}^{t}}{1-\beta_{1}}$. Substituting this back in gives us the final result:</p>
<p>$$ E[m_{t}] = E[g] \cdot (1 - \beta_1) (\frac{1 - \beta_1^t}{1 - \beta_1}) = E[g] \cdot (1 - \beta_1^t) $$</p>
<p>This proves that the expected value of our moment estimate $m_t$ is not the true moment $E[g]$. It is off by a factor of $(1-\beta_1^t)$. This is the mathematical definition of the bias.</p>
<p><strong>A Practical Example: A Cold Start:</strong></p>
<p>Both $m_{t}$ and $v_{t}$ are initialized as vectors of zeros. Let&rsquo;s look at what happens on the very first step ($t=1$), with $\beta_{1} = 0.9$:</p>
<p>$$ m_{1} = 0.9 \cdot (0) + 0.1 \cdot g_{1} = 0.1 \cdot g_{1} $$</p>
<p>The first moment estimate is only 10% of the actual first gradient. The estimate is heavily <strong>biased towards zero</strong>,  exactly as our derived bias factor of $(1 - 0.9^1) = 0.1$ predicted. This makes the initial steps of the optimizer unnecessarily small and inefficient. It needs a &ldquo;warm-up&rdquo; period for the moment estimates to catch up to their true values.</p>
<p><strong>Deriving the Correction:</strong></p>
<p>To create an unbiased estimator $\hat{m}_t$ such that $E[\hat{m}_t] = E[g]$, we simply need to counteract the bias factor we derived. Starting from our result:</p>
<p>$$E[m_t] = E[g] (1-\beta_1^t)$$We can rearrange it to define an unbiased estimate of $E[g]$:</p>
<p>$$E[g] = \frac{E[m_t]}{1-\beta_1^t} = E\left[\frac{m_t}{1-\beta_1^t}\right]$$</p>
<p>This directly gives us the bias-corrected estimators for both moments:</p>
<p>$$\hat{m}_t = \frac{m_t}{1 - \beta_1^t} \quad \text{and} \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}$$</p>
<p>Let&rsquo;s see this correction in action on our <code>$t=1$</code> example:</p>
<p>$$\hat{m}_1 = \frac{m_1}{1 - 0.9^1} = \frac{0.1 \cdot g_1}{0.1} = g_1$$</p>
<p>The correction perfectly cancels the bias, ensuring the estimate is accurate from the very first step.</p>
<h4 id="4-putting-it-all-together-the-final-update-rule"><strong>4. Putting It All Together: The Final Update Rule</strong><a hidden class="anchor" aria-hidden="true" href="#4-putting-it-all-together-the-final-update-rule">#</a></h4>
<p>The final update rule is a combination:</p>
<p>$$\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v} + \epsilon}} \hat{m_{t}}$$</p>
<ul>
<li>We take the <strong>direction</strong> from the corrected 1st moment, $\hat{m}_t$ (the Momentum part).</li>
<li>We divide it by the square root of the corrected 2nd moment, $\sqrt{\hat{v}_t}$ (the RMSprop part), which normalizes the step size on a per-parameter basis.</li>
<li>We scale the whole thing by a global learning rate $\eta$.</li>
</ul>
<p>This is how Adam effectively takes the best from its predecessors and combines them into a single, robust algorithm.</p>
<h2 id="adamw-adam-with-decoupled-weight-decay">AdamW [Adam with Decoupled Weight Decay]<a hidden class="anchor" aria-hidden="true" href="#adamw-adam-with-decoupled-weight-decay">#</a></h2>
<p>As models, especially Transformers became more comples, something was bit off with how Adam handled a common regularization technique called <strong>weight decay</strong>. AdamW is the fix.</p>
<hr>
<h3 id="the-intuitive-idea-1"><em><strong>The Intuitive Idea</strong></em><a hidden class="anchor" aria-hidden="true" href="#the-intuitive-idea-1">#</a></h3>
<p><strong>The Problem:</strong> To prevent our models from getting too complex and &ldquo;memorizing&rdquo; the training data (overfitting), we often use a technique called <strong>L2 Regularization</strong>. Think of it as a penalty for having large parameter values. It encourages the model to keep its &ldquo;knobs&rdquo; (weights) small and simple.</p>
<p>In optimizers like SGD, this is implemented as <strong>weight decay</strong>, where you subtract a tiny fraction of the weight from itself at every step. It&rsquo;s like a small tax on the weights, forcing them to shrink, or &ldquo;decay,&rdquo; over time.</p>
<p>We assumed L2 Regularization and weight decay were the same thing and implemented them that way. So, Adam&rsquo;s implementation mixed the weight decay &ldquo;tax&rdquo; in with the gradient.</p>
<p><strong>The Big Idea:</strong> Imagine you&rsquo;re trying to roll our &ldquo;heavy ball&rdquo; (from Momentum) downhill. The <strong>gradient</strong> is the force of gravity pulling it down the slope. <strong>Weight decay</strong> is like a gentle, constant breeze that always pushes the ball towards the center of the valley (towards zero).</p>
<ul>
<li><em>Adam&rsquo;s Mistake:</em> Adam mixed the &ldquo;breeze&rdquo; (weight decay) in with the &ldquo;gravity&rdquo; (gradient). This seems fine, but Adam&rsquo;s adaptive machinery ($\sqrt{\hat{v}_t}$) scales both forces together. So, if a parameter has had large gradients in the past, Adam shrinks the learning rate for both the gravity and the breeze for that parameter. The breeze shouldn&rsquo;t be scaled; it should be constant.</li>
<li><em>AdamW&rsquo;s Fix:</em> AdamW (Adam with Weight Decay) is simple. It says, &ldquo;Don&rsquo;t mix the two forces.&rdquo; It first calculates the step using only gravity (the gradient), just like regular Adam. Then, as a completely separate step, it applies the gentle breeze (the weight decay tax). This is called <strong>decoupled weight decay</strong>.</li>
</ul>
<p><strong>The Outcome:</strong> This simple change makes a huge difference. The regularization becomes much more effective and predictable. For training large models like Transformers, AdamW almost always performs better than Adam and is now the recommended default optimizer.</p>
<hr>
<h3 id="the-techincal-dive"><em><strong>The Techincal Dive</strong></em><a hidden class="anchor" aria-hidden="true" href="#the-techincal-dive">#</a></h3>
<p>The difference between Adam and AdamW is subtle but mathematically significant. It all comes down to how L2 regularization is implemented.</p>
<h4 id="l2-regularizatoin-vs-weight-decay">L2 Regularizatoin vs Weight Decay<a hidden class="anchor" aria-hidden="true" href="#l2-regularizatoin-vs-weight-decay">#</a></h4>
<p>in its pure form, <strong>L2 Regularization</strong> modifies the loss function by adding a penalty term:</p>
<p>$$J_{L2}(\theta) = J_{original}(\theta) + \frac{\lambda}{2} \sum_{i} \theta_{i}^{2} $$</p>
<p>When you take the derivative of this new loss function, the gradient becomes:</p>
<p>$$ \nabla_{\theta} J_{L2} (\theta) = \nabla_{\theta} J_{original} (\theta) + \lambda \theta $$
Here, $\lambda$ is the regularization strength.</p>
<h4 id="how-adam-implements-it-incorrectly">How Adam Implements It (Incorrectly):<a hidden class="anchor" aria-hidden="true" href="#how-adam-implements-it-incorrectly">#</a></h4>
<p>Adaptive optimizers like Adam use moving averages ($m_t$ and $v_t$) of the gradient. In standard libraries, the L2 term ($\lambda\theta$) was simply added to the gradient $g_t$ before being passed to the optimizer.</p>
<p>L2 regularization results in a gradient of $g_t + \lambda\theta_t$, where $g_t = \nabla_{\theta}J_{original}(\theta_t)$.</p>
<p>When this combined gradient is fed into the Adam algorithm, the moment estimates become:</p>
<ul>
<li>1st Moment: $m_t = \beta_1 m_{t-1} + (1 - \beta_1) (g_t + \lambda\theta_t)$</li>
<li>2nd Moment: $v_t = \beta_2 v_{t-1} + (1 - \beta_2) (g_t + \lambda\theta_t)^2$</li>
</ul>
<p>The final update rule (ignoring bias correction for simplicity) is:
$$\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{v_t} + \epsilon} m_t$$
Notice that the weight decay term $\lambda\theta_t$ is now inside the moving averages. This means the adaptive denominator $\sqrt{v_t}$ scales both the gradient and the weight decay. If a particular weight has a large historical gradient magnitude, its corresponding $v_t$ will be large. This shrinks the update from the original gradient (which is desirable) but also shrinks the effect of the weight decay $\lambda\theta_t$ (which is not). The regularization becomes less effective for parameters that need it most.</p>
<h4 id="how-adamw-implements-weight-decay-the-decoupled-approach">How AdamW Implements Weight Decay (The Decoupled Approach):<a hidden class="anchor" aria-hidden="true" href="#how-adamw-implements-weight-decay-the-decoupled-approach">#</a></h4>
<p>AdamW decouples the weight decay from the gradient update.</p>
<ol>
<li>
<p>The moment estimates are updated using only the original gradient $g_t$:</p>
<p>1st Moment: $m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$</p>
<p>2nd Moment: $v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2$</p>
</li>
<li>
<p>The adaptive Adam step is calculated from these moments::</p>
</li>
</ol>
<p>$$(\text{Adam Step})_t = \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$$</p>
<p>where $m_t$ and $v_t$ are computed using only $\nabla_{\theta}J_{original}(\theta_t)$.</p>
<p>The final update applies this step and then subtracts the decay term directly:</p>
<p>$$\theta_{t+1} = \theta_t - (\text{Adam Step})_t - \eta \lambda \theta_t$$</p>
<p>Crucially, the weight decay term - $\eta \lambda \theta_t$ is not affected by the adaptive moment estimates. The decay is proportional only to the weight&rsquo;s current value and the learning rate, making the regularization behave exactly as intended.</p>
<p>This decoupling ensures that the optimizer&rsquo;s adaptivity is used to navigate the loss landscape (via the gradients), while weight decay serves its distinct purpose as a regularizer, shrinking weights towards zero at a predictable rate. This makes training more stable and allows for better generalization, particularly in models sensitive to regularization like Transformers.</p>
<h3 id="the-practical-impact-better-hyperparameter-tuning">The Practical Impact: Better Hyperparameter Tuning<a hidden class="anchor" aria-hidden="true" href="#the-practical-impact-better-hyperparameter-tuning">#</a></h3>
<p>The main benefit of decoupling is that it makes the hyperparameters easier to tune and more independent of each other.</p>
<p>Think of it like tuning an old stereo system:</p>
<ul>
<li>
<p><strong>In Standard Adam:</strong> the learning rate ($\eta$) and the L2 regularization factor ($\lambda$) are coupled. This is because the weight decay term $\lambda\theta_t$ is included in the gradient before the moment estimation. Consequently, the final update for a given parameter is scaled by $\frac{\eta}{\sqrt{\hat{v}_t} + \epsilon}$. This means the effective weight decay is influenced by both $\lambda$ and the historical gradients stored in $\hat{v}_t$. As a result, changing the learning rate $\eta$ or the initial parameter scale alters the effective magnitude of the weight decay, making it difficult to tune the two hyperparameters independently.</p>
</li>
<li>
<p><strong>in AdamW:</strong> the weight decay is decoupled from the adaptive mechanism. The update from weight decay is simply $- \eta \lambda \theta_t$. The effect of the $\lambda$ hyperparameter is now scaled only by the learning rate $\eta$, not by the adaptive denominator $\sqrt{\hat{v}_t}$ which contains the gradient history. This makes the relationship between the learning rate and weight decay much more predictable. You can tune the regularization strength $\lambda$ with a more consistent expectation of its effect, regardless of the adaptivity, creating a more orthogonal and effective search for optimal hyperparameters.</p>
</li>
</ul>
<p>This decoupling allows you to find better final models because the optimal learning rate is less dependent on your choice of weight decay, and vice-versa. You have finer control, which often leads to better overall performance.</p>
<h3 id="with-learning-rate-schedulers">With Learning Rate Schedulers<a hidden class="anchor" aria-hidden="true" href="#with-learning-rate-schedulers">#</a></h3>
<p>Decoupled weight decay works much better with learning rate schedulers (like cosine annealing, where the learning rate starts high and gradually decreases).</p>
<p>With standard Adam, as the learning rate $\eta$ decays, the effective strength of the weight decay also shrinks in a coupled, often unpredictable way. With AdamW, the effect is cleaner. This allows for more aggressive learning rate schedules, which can help the model settle into better, wider minima in the loss landscape, further improving generalization.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lav-aniya.github.io/tags/optimization/">Optimization</a></li>
      <li><a href="https://lav-aniya.github.io/tags/deep-learning/">Deep Learning</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://lav-aniya.github.io/blogs/optimizers2/">
    <span class="title">« Prev</span>
    <br>
    <span>O2</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share O3 on x"
            href="https://x.com/intent/tweet/?text=O3&amp;url=https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f&amp;hashtags=Optimization%2cDeepLearning">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share O3 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f&amp;title=O3&amp;summary=O3&amp;source=https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share O3 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f&title=O3">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share O3 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share O3 on whatsapp"
            href="https://api.whatsapp.com/send?text=O3%20-%20https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share O3 on telegram"
            href="https://telegram.me/share/url?text=O3&amp;url=https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share O3 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=O3&u=https%3a%2f%2flav-aniya.github.io%2fblogs%2foptimizers3%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lav-aniya.github.io/">Lav-Aniya&#39;s Site</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
